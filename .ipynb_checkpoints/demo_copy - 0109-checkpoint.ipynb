{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unity Communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../simulation/')\n",
    "from unity_simulator.comm_unity import UnityCommunication\n",
    "comm = UnityCommunication()\n",
    "comm.reset(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['close', 'drink', 'find', 'grab', 'look_at', 'open', 'point_at', 'put_back', 'put_in', 'read', 'run', 'sit', 'stand_up', 'switch_off', 'switch_on', 'touch', 'turn_to', 'walk', 'watch', 'walk_to_wards', 'walk_for_ward', 'turn_left', 'turn_right']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from email import header\n",
    "\n",
    "csv_file = open(\"./action_list.csv\", \"r\", encoding=\"ms932\", errors=\"\", newline=\"\" )\n",
    "f = csv.reader(csv_file, delimiter=\",\", doublequote=True, lineterminator=\"\\r\\n\", quotechar='\"', skipinitialspace=True)\n",
    "\n",
    "action_list = [row[0] for row in f]\n",
    "print(action_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'bananas', 'barsoap', 'bathroom', 'bathroomcabinet', 'bathroomcounter', 'bathtub', 'bed', 'bedroom', 'bellpepper', 'bench', 'book', 'bookshelf', 'box', 'breadslice', 'cabinet', 'candle', 'candybar', 'ceiling', 'ceilinglamp', 'cellphone', 'cereal', 'chair', 'chips', 'chocolatesyrup', 'clock', 'closet', 'closetdrawer', 'clothespants', 'clothespile', 'clothesshirt', 'coffeetable', 'computer', 'condimentbottle', 'condimentshaker', 'crackers', 'creamybuns', 'cupcake', 'curtains', 'cutleryfork', 'cutleryknife', 'deodorant', 'desk', 'dishbowl', 'dishwashingliquid', 'door', 'doorjamb', 'facecream', 'faucet', 'floor', 'folder', 'fridge', 'fryingpan', 'garbagecan', 'hairproduct', 'hanger', 'keyboard', 'kitchen', 'kitchencabinet', 'kitchencounter', 'kitchencounterdrawer', 'kitchentable', 'lightswitch', 'livingroom', 'microwave', 'mouse', 'mousemat', 'mug', 'nightstand', 'orchid', 'painkillers', 'paper', 'peach', 'perfume', 'photoframe', 'pie', 'pillow', 'plate', 'plum', 'powersocket', 'radio', 'remotecontrol', 'rug', 'salmon', 'sink', 'slippers', 'sofa', 'stall', 'stove', 'stovefan', 'toaster', 'toilet', 'toothbrush', 'toothpaste', 'towel', 'towelrack', 'tv', 'tvstand', 'wall', 'walllamp', 'wallphone', 'wallpictureframe', 'wallshelf', 'washingmachine', 'washingsponge', 'waterglass', 'whippedcream', 'window', 'wineglass']\n"
     ]
    }
   ],
   "source": [
    "s, graph = comm.environment_graph()\n",
    "nodes = graph['nodes']\n",
    "\n",
    "object_list = [n.get('class_name') for n in nodes]\n",
    "notExecutable_object = {'coffeemaker', 'coffeepot', 'cpuscreen', 'tablelamp', 'lime', 'oventray'}\n",
    "\n",
    "object_list = sorted(list(set(object_list) - notExecutable_object))\n",
    "print(object_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bathroom', 'bedroom', 'bowl', 'cd_player', 'chair', 'coffee_cup', 'coffee_table', 'computer', 'controller', 'couch', 'cup', 'desk', 'dining_room', 'faucet', 'filing_cabinet', 'food_food', 'freezer', 'home_office', 'keyboard', 'kitchen_cabinet', 'kitchen_counter', 'light', 'microwave', 'mouse', 'novel', 'oven', 'phone', 'plate', 'remote_control', 'shower', 'sink', 'stereo', 'table', 'television', 'toilet', 'tooth_paste', 'toothbrush', 'water_glass']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "from numpy import append\n",
    "\n",
    "script_object_list = set()\n",
    "\n",
    "files = glob.glob(\"executable/*.txt\")\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        file_data = f.readlines()[4:]\n",
    "\n",
    "        for line in file_data:\n",
    "            row = line.split()\n",
    "            if len(row)==3:\n",
    "                script_object_list.add(str(row[1]).replace(\"<\", \"\").replace(\">\",\"\"))\n",
    "            elif len(row)==5:\n",
    "                script_object_list.add(str(row[3]).replace(\"<\", \"\").replace(\">\",\"\"))\n",
    "\n",
    "script_object_list = sorted(list(script_object_list))\n",
    "print(script_object_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['after_shave', 'alarm_clock', 'basket_for_clothes', 'bathroom_cabinet', 'bathroom_counter', 'bowl', 'carpet', 'cd_player', 'check', 'cleaning_bottle', 'cleaning_solution', 'cloth_napkin', 'coffee_cup', 'coffee_table', 'controller', 'couch', 'cup', 'cupboard', 'curtain', 'detergent', 'dining_room', 'dish_soap', 'document', 'drawing', 'dresser', 'drinking_glass', 'entrance_hall', 'face_soap', 'facial_cleanser', 'filing_cabinet', 'food_apple', 'food_bread', 'food_cereal', 'food_dessert', 'food_fish', 'food_food', 'food_fruit', 'food_oatmeal', 'food_salt', 'food_snack', 'food_sugar', 'fork', 'freezer', 'garbage_can', 'glass', 'groceries', 'home_office', 'kitchen_cabinet', 'kitchen_counter', 'knife', 'light', 'lighting', 'living_room', 'love_seat', 'mat', 'mousepad', 'mug', 'napkin', 'notes', 'novel', 'oil', 'oven', 'painting', 'paper_towel', 'phone', 'pot', 'printing_paper', 'receipt', 'remote_control', 'sauce', 'sauce_pan', 'shampoo', 'shoes', 'shower', 'soap', 'sponge', 'stereo', 'table', 'telephone', 'television', 'textbook', 'toilet_paper', 'tooth_paste', 'towel_rack', 'trashcan', 'wall_clock', 'water_glass', 'wine_glass']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_open = open('class_name_equivalence_new.json', 'r')\n",
    "object_name_equivalence = json.load(json_open)\n",
    "\n",
    "# virtualhomeで定義された object_list中の同義語一覧\n",
    "equivalence_object = [k for obj in object_list for k, v in object_name_equivalence.items() if obj in str(v).replace(\"_\",\"\")]\n",
    "equivalence_object = sorted(list(set(equivalence_object)))\n",
    "print(sorted(equivalence_object))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Room List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bathroom', 'bedroom', 'kitchen', 'livingroom']\n"
     ]
    }
   ],
   "source": [
    "room_list = [n.get(\"class_name\") for n in nodes if n.get(\"category\") == \"Rooms\"]\n",
    "print(room_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bathroom : ['barsoap', 'bathroomcabinet', 'bathroomcounter', 'bathtub', 'candle', 'ceiling', 'ceilinglamp', 'curtains', 'deodorant', 'door', 'doorjamb', 'facecream', 'faucet', 'floor', 'hairproduct', 'lightswitch', 'painkillers', 'perfume', 'plate', 'rug', 'stall', 'toilet', 'toothbrush', 'toothpaste', 'towel', 'towelrack', 'wall', 'walllamp', 'wallshelf', 'washingmachine', 'waterglass', 'window']\n",
      "bedroom : ['bed', 'book', 'bookshelf', 'box', 'candle', 'ceiling', 'ceilinglamp', 'cellphone', 'chair', 'closet', 'closetdrawer', 'clothespants', 'clothespile', 'clothesshirt', 'coffeetable', 'computer', 'cupcake', 'curtains', 'desk', 'doorjamb', 'floor', 'folder', 'garbagecan', 'hanger', 'keyboard', 'lightswitch', 'mouse', 'mousemat', 'mug', 'nightstand', 'orchid', 'photoframe', 'pillow', 'plate', 'radio', 'rug', 'slippers', 'wall', 'wallpictureframe', 'window', 'wineglass']\n",
      "kitchen : ['bananas', 'bellpepper', 'bench', 'book', 'bookshelf', 'box', 'breadslice', 'candybar', 'ceiling', 'ceilinglamp', 'cereal', 'chips', 'chocolatesyrup', 'clock', 'clothespile', 'condimentbottle', 'condimentshaker', 'crackers', 'creamybuns', 'cutleryfork', 'cutleryknife', 'dishbowl', 'dishwashingliquid', 'door', 'faucet', 'floor', 'fridge', 'fryingpan', 'kitchencabinet', 'kitchencounter', 'kitchencounterdrawer', 'kitchentable', 'lightswitch', 'microwave', 'orchid', 'paper', 'photoframe', 'pie', 'plate', 'powersocket', 'rug', 'salmon', 'sink', 'stove', 'stovefan', 'toaster', 'tv', 'tvstand', 'wall', 'wallphone', 'wallpictureframe', 'wallshelf', 'washingsponge', 'waterglass', 'whippedcream', 'wineglass']\n",
      "livingroom : ['apple', 'bananas', 'book', 'bookshelf', 'box', 'cabinet', 'ceiling', 'ceilinglamp', 'cellphone', 'chair', 'closet', 'closetdrawer', 'clothespants', 'clothespile', 'clothesshirt', 'coffeetable', 'computer', 'curtains', 'desk', 'dishbowl', 'doorjamb', 'floor', 'folder', 'hanger', 'keyboard', 'lightswitch', 'mouse', 'mousemat', 'mug', 'paper', 'peach', 'photoframe', 'pillow', 'plum', 'powersocket', 'remotecontrol', 'rug', 'sofa', 'tv', 'tvstand', 'wall', 'walllamp', 'wallpictureframe', 'window']\n"
     ]
    }
   ],
   "source": [
    "bathroom_id = 0\n",
    "bedroom_id = 0\n",
    "kitchen_id = 0\n",
    "livingroom_id = 0\n",
    "\n",
    "for n in nodes:\n",
    "    if n.get(\"class_name\") in room_list:\n",
    "        if n.get(\"class_name\")==\"bathroom\":\n",
    "            bathroom_id = n.get(\"id\")\n",
    "            \n",
    "        elif n.get(\"class_name\")==\"bedroom\":\n",
    "            bedroom_id = n.get(\"id\")\n",
    "            \n",
    "        elif n.get(\"class_name\")==\"kitchen\":\n",
    "            kitchen_id = n.get(\"id\")\n",
    "            \n",
    "        elif n.get(\"class_name\")==\"livingroom\":\n",
    "            livingroom_id = n.get(\"id\")\n",
    "\n",
    "bathroom_objects = []\n",
    "bedroom_objects = []\n",
    "kitchen_objects = []\n",
    "livingroom_objects = []\n",
    "\n",
    "edges = graph['edges']\n",
    "\n",
    "for e in edges:\n",
    "    if e.get(\"to_id\") == bathroom_id and e.get(\"relation_type\") == \"INSIDE\":\n",
    "        bathroom_objects.append([n.get(\"class_name\") for n in nodes if n.get(\"id\") == e.get(\"from_id\")][0])\n",
    "        \n",
    "    elif e.get(\"to_id\") == bedroom_id and e.get(\"relation_type\") == \"INSIDE\":\n",
    "        bedroom_objects.append([n.get(\"class_name\") for n in nodes if n.get(\"id\") == e.get(\"from_id\")][0])\n",
    "    \n",
    "    elif e.get(\"to_id\") == kitchen_id and e.get(\"relation_type\") == \"INSIDE\":\n",
    "        kitchen_objects.append([n.get(\"class_name\") for n in nodes if n.get(\"id\") == e.get(\"from_id\")][0])\n",
    "    \n",
    "    elif e.get(\"to_id\") == livingroom_id and e.get(\"relation_type\") == \"INSIDE\":\n",
    "        livingroom_objects.append([n.get(\"class_name\") for n in nodes if n.get(\"id\") == e.get(\"from_id\")][0])\n",
    "        \n",
    "bathroom_objects = sorted(list(set(bathroom_objects) - notExecutable_object))\n",
    "bedroom_objects = sorted(list(set(bedroom_objects) - notExecutable_object))\n",
    "kitchen_objects = sorted(list(set(kitchen_objects) - notExecutable_object))\n",
    "livingroom_objects = sorted(list(set(livingroom_objects) - notExecutable_object))\n",
    "\n",
    "room_dict = {\"bathroom\":bathroom_objects, \"bedroom\":bedroom_objects, \"kitchen\":kitchen_objects, \"livingroom\":livingroom_objects}\n",
    "\n",
    "print('bathroom : ' + str(bathroom_objects))\n",
    "print('bedroom : ' + str(bedroom_objects))\n",
    "print('kitchen : ' + str(kitchen_objects))\n",
    "print('livingroom : ' + str(livingroom_objects))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "\n",
    "    for word in wn.synsets(word)[:5]:\n",
    "        synonyms.add(str(word.name()).split('.')[0])\n",
    "\n",
    "    return(synonyms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 17:58:33,123 : INFO : loading projection weights from C:\\Users\\j-aoyama/gensim-data\\word2vec-google-news-300\\word2vec-google-news-300.gz\n",
      "2023-01-09 17:58:57,747 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from C:\\\\Users\\\\j-aoyama/gensim-data\\\\word2vec-google-news-300\\\\word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2023-01-09T17:58:57.747208', 'gensim': '4.2.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_object(word):\n",
    "    point = 0\n",
    "    similar_object = \"\"\n",
    "\n",
    "    for object in object_list:\n",
    "\n",
    "        try:\n",
    "            if wv.similarity(word, object) > point:\n",
    "                point = wv.similarity(word, object)\n",
    "                similar_object = object\n",
    "\n",
    "        except KeyError:\n",
    "            pass\n",
    "    \n",
    "    if point > 0.5:\n",
    "        return similar_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j-aoyama\\Anaconda3\\envs\\vh2kg\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['watch', 'mute', 'hate', 'ignore', 'turn']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model = pipeline(\"fill-mask\")\n",
    "\n",
    "def fill_mask(word, num, text): #word <- 空欄にする単語     num <- wordの対象が複数ある時に対象とする場所を示す     text <- sentence\n",
    "    doc = nlp(text)\n",
    "    mask_text = \"\"\n",
    "    count = 0\n",
    "    for token in doc:\n",
    "        if token.text == word:\n",
    "            if num == count:\n",
    "                mask_text += \"{} \"\n",
    "            else:\n",
    "                mask_text += token.text + \" \"\n",
    "\n",
    "            count += 1   \n",
    "        else:\n",
    "            mask_text += token.text + \" \"\n",
    "    #print(mask_text)\n",
    "    \n",
    "    inputs = [mask_text.format(model.tokenizer.mask_token)]\n",
    "    #print(inputs)\n",
    "    res = model(inputs, top_k=5)\n",
    "    return [str(r[\"token_str\"]).replace(\" \", \"\") for r in res]\n",
    "\n",
    "fill_mask(\"watch\", 0, \"I turn on the tv and sit in the sofa. I watch the tv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to Present tense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def present_tense(text): # 動詞の活用形を現在形に直して返す\n",
    "    for token in nlp(str(text).replace(\"_\",\" \")):\n",
    "        if token.pos_== 'VERB':\n",
    "            text = str(text).replace(token.text, token.lemma_)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision action and object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_action_object(verb, pharasal_verb, object, sentence, num):\n",
    "\n",
    "    decision_action = None\n",
    "    decision_object = []\n",
    "\n",
    "    # 動詞の決定\n",
    "    if pharasal_verb:\n",
    "        if present_tense(pharasal_verb) in action_list: # 句動詞がアクションリストに存在するか\n",
    "            decision_action = str(present_tense(pharasal_verb))\n",
    "\n",
    "        elif get_synonyms(present_tense(pharasal_verb)) & set(action_list): # 句動詞の同義語（WordNetで検索）がアクションリストに存在するか\n",
    "            mached_list = list(get_synonyms(present_tense(pharasal_verb)) & set(action_list))\n",
    "\n",
    "            if len(mached_list)==1:\n",
    "                decision_action = mached_list[0]\n",
    "            #else:\n",
    "                #類似度の高いほう\n",
    "\n",
    "    if decision_action is None:\n",
    "        if present_tense(verb) in action_list: # 動詞がアクションリストに存在するか\n",
    "            decision_action = present_tense(verb)\n",
    "\n",
    "        elif get_synonyms(present_tense(verb)) & set(action_list): # 動詞の同義語（WordNetで検索）がアクションリストに存在するか\n",
    "            mached_list = list(get_synonyms(present_tense(verb)) & set(action_list))\n",
    "\n",
    "            if len(mached_list)==1:\n",
    "                decision_action = mached_list[0]\n",
    "            #else:\n",
    "                #類似度の高いほう\n",
    "\n",
    "        else:\n",
    "            candidate_action = fill_mask(verb, num, sentence) # 文章中の動詞を空欄にして空欄部分に入りそうな動詞の候補を取得\n",
    "            #print(candidate_action)\n",
    "            for action in candidate_action: \n",
    "                action = present_tense(action)\n",
    "                if action in action_list: # 候補中の動詞がアクションリストに存在すれば決定する\n",
    "                    decision_action = action\n",
    "                    break\n",
    "                elif pharasal_verb: # 句動詞がある場合 候補中の動詞+前置詞 がアクションリストに存在するか\n",
    "                    action = action + \"_\" + str(pharasal_verb).rsplit(\"_\")[1]\n",
    "                    if action in action_list:\n",
    "                        decision_action = action\n",
    "                        break\n",
    "                #<- 複数存在する場合にどうするか？　オブジェクトのプロパティから実行できるか？　部屋の場合はWalkにしてしまうのか？\n",
    "\n",
    "            #if decision_action is None: # 見つからなかったときに類似度で出すか？\n",
    "                #decision_action = get_similar_action(verb)\n",
    "\n",
    "    for obj in object:\n",
    "\n",
    "        if obj in object_list: # オブジェクトがオブジェクトリストに存在するか\n",
    "            decision_object.append(obj)\n",
    "\n",
    "        elif obj in equivalence_object: # オブジェクトがVirtualhomeが定義しているオブジェクトリスト中の同義語一覧に存在する場合\n",
    "            decision_object.append(list(set(object_name_equivalence.get(obj)) & set(object_list))[0]) # オブジェクトのVirtualhomeで定義された同義語とオブジェクトリストの共通集合から取得\n",
    "\n",
    "        # \"_\" が文字列に含まれている場合\n",
    "        elif \"_\" in str(obj): \n",
    "            obj = str(obj).replace(\"_\",\"\")  # \"_\" を外して上記と同じことをする\n",
    "            if obj in object_list:\n",
    "                decision_object.append(obj)\n",
    "\n",
    "            elif obj in equivalence_object:\n",
    "                decision_object.append(list(set(object_name_equivalence.get(obj)) & set(object_list))[0])\n",
    "\n",
    "        elif set(get_synonyms(obj)) & set(object_list):\n",
    "            mached_list = list(get_synonyms(obj) & set(object_list))\n",
    "\n",
    "            if len(mached_list)==1:\n",
    "                decision_object.append(mached_list[0])\n",
    "\n",
    "            #else:\n",
    "                #類似度の高いほう\n",
    "\n",
    "        elif set(get_synonyms(obj)) & set(equivalence_object):\n",
    "            mached_list = list(get_synonyms(obj) & set(equivalence_object))\n",
    "            #print(mached_list)\n",
    "\n",
    "            if len(mached_list)==1:\n",
    "                decision_object.append(list(set(object_name_equivalence.get(mached_list[0])) & set(object_list))[0])\n",
    "\n",
    "            #else:\n",
    "                #類似度の高いほう\n",
    "\n",
    "        elif get_similar_object(obj):\n",
    "            decision_object.append(get_similar_object(obj))\n",
    "    \n",
    "    if \"\" in decision_object:\n",
    "        decision_object.remove(\"\")\n",
    "    \n",
    "    return decision_action, decision_object\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morphological analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphological_analysis(text):\n",
    "    sentence_list = []\n",
    "    sentence = \"\"\n",
    "\n",
    "    for i, token in enumerate(text):\n",
    "\n",
    "        if token.text==\".\":\n",
    "            sentence = sentence.rstrip() + \".\"\n",
    "            sentence_list.append(nlp(sentence))\n",
    "            sentence = \"\"\n",
    "        elif len(text)-1 == i:\n",
    "            sentence += str(token.text).lower() + \".\"\n",
    "            sentence_list.append(nlp(sentence))\n",
    "        elif sentence == \"\" and token.tag_ != \"PRP\":#token.pos_ == \"VERB\"\n",
    "            sentence += \"I \" + str(token.text).lower() + \" \"\n",
    "        elif token.tag_ == \"PRP\":\n",
    "            sentence += token.text + \" \"\n",
    "        else:\n",
    "            sentence += str(token.text).lower() + \" \"    \n",
    "\n",
    "    #print(sentence_list)\n",
    "    doc = \"\"\n",
    "    for sentence in sentence_list:\n",
    "        doc += str(sentence) + \" \"\n",
    "\n",
    "    pair_dict_list = []\n",
    "    for subActivity_doc in sentence_list:\n",
    "        verb = None     #動詞\n",
    "        prep = None     #前置詞修飾詞\n",
    "        prt = None      #句動詞助詞\n",
    "        comp = None     #補語\n",
    "        object = []     #目的語\n",
    "        compound = None #複合修飾詞\n",
    "        pharasal_verb = None    #句動詞\n",
    "        #adverb = None  #副詞\n",
    "\n",
    "        for token in subActivity_doc:\n",
    "            #print(token.text, token.tag_, token.pos_, token.head.text, token.dep_)\n",
    "\n",
    "            if (token.dep_ == \"ROOT\" or token.dep_ == \"conj\" or token.dep_ == \"dep\" or token.dep_ == \"advcl\" or token.dep_ == \"ccomp\" or token.dep_ == \"xcomp\" or token.dep_ == \"pcomp\") and token.pos_ == \"VERB\": #token.pos_ == \"VERB\": \n",
    "                if verb or pharasal_verb:\n",
    "                    # 辞書形式でアクションとオブジェクトのペアを追加\n",
    "                    pair_dict = {}\n",
    "                    if pharasal_verb:\n",
    "                        pair_dict.setdefault(\"action\", pharasal_verb)\n",
    "                        pharasal_verb = None\n",
    "                    else:\n",
    "                        pair_dict.setdefault(\"action\", verb)\n",
    "\n",
    "                    object =  [obj for obj in object]\n",
    "                    pair_dict.setdefault(\"object\", object)\n",
    "                    #pair_dict.setdefault(\"sentence\", doc)\n",
    "                    pair_dict_list.append(pair_dict)\n",
    "                    # 空にする\n",
    "                    verb = None\n",
    "                    object = []\n",
    "\n",
    "                verb = token.text\n",
    "\n",
    "            elif token.dep_ == \"dobj\" and token.head.text == verb or token.dep_ == \"pobj\" and (token.head.text == prep or token.head.text == prt):\n",
    "                if token.text == \"it\":\n",
    "                    if pair_dict_list:\n",
    "                        if pair_dict_list[-1].get(\"object\"):\n",
    "                            object.append(pair_dict_list[-1].get(\"object\")[-1])\n",
    "                elif compound:#<- \n",
    "                    object.append(compound + \"_\" + token.text)\n",
    "                    compound = None\n",
    "                else:\n",
    "                    object.append(token.text)\n",
    "\n",
    "            elif token.dep_ == \"prt\" and token.head.text == verb:\n",
    "                prt = token.text\n",
    "                if not pharasal_verb:\n",
    "                    pharasal_verb = verb + \"_\" + prt\n",
    "\n",
    "            elif token.dep_ == \"prep\" and token.head.text == verb:\n",
    "                prep = token.text\n",
    "                if not pharasal_verb:\n",
    "                    pharasal_verb = verb + \"_\" + prep #改善\n",
    "            \n",
    "            elif token.dep_ == \"conj\" and token.pos_ == \"NOUN\":\n",
    "                if compound:#<- \n",
    "                    object .append(compound + \"_\" + token.text)\n",
    "                    compound = None\n",
    "                else:\n",
    "                    object.append(token.text)\n",
    "\n",
    "            elif token.dep_ == \"compound\":\n",
    "                compound = token.text\n",
    "\n",
    "            elif token.dep_ == \"punct\" and token.text == \".\":\n",
    "                # 辞書形式でアクションとオブジェクトのペアを追加\n",
    "                pair_dict = {}\n",
    "                if pharasal_verb:\n",
    "                    pair_dict.setdefault(\"action\", pharasal_verb)\n",
    "                    pharasal_verb = None\n",
    "                else:\n",
    "                    pair_dict.setdefault(\"action\", verb)\n",
    "\n",
    "                object =  [obj for obj in object]   \n",
    "                pair_dict.setdefault(\"object\", object)\n",
    "                #pair_dict.setdefault(\"sentence\", doc)\n",
    "                pair_dict_list.append(pair_dict)\n",
    "\n",
    "    #print(pair_dict_list)\n",
    "    #print(doc)\n",
    "    return pair_dict_list, doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# そのオブジェクトまで歩いて近づく必要のないアクション\n",
    "noNeedToWalk = [\"look_at\", \"watch\"] #<- turn_to??\n",
    "\n",
    "# 事前に turn_to が必要なアクション\n",
    "needTurnTo = [\"look_at\"]\n",
    "\n",
    "# オブジェクトを対象としないアクション\n",
    "noObjAction = [\"stand_up\",\"turn_left\",\"turn_right\"]\n",
    "\n",
    "# 2つのオブジェクトを対象とするアクション\n",
    "twoObjAction = [\"put_in\", \"put_back\"]\n",
    "\n",
    "# 座りながらできないアクション\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_object = []\n",
    "grab_object = []\n",
    "switch_on_object = []\n",
    "open_object = []\n",
    "\n",
    "can_open_object = []\n",
    "sittable_object = []\n",
    "grabbable_object = []\n",
    "has_switch_object = []\n",
    "drinkable_object = []\n",
    "readable_object = []\n",
    "\n",
    "for n in nodes:\n",
    "    properties = n.get(\"properties\")\n",
    "    if \"CAN_OPEN\" in properties:\n",
    "        can_open_object.append(n.get(\"class_name\"))\n",
    "    if \"SITTABLE\" in properties:\n",
    "        sittable_object.append(n.get(\"class_name\"))\n",
    "    if \"GRABBABLE\" in properties:\n",
    "        grabbable_object.append(n.get(\"class_name\"))\n",
    "    if \"HAS_SWITCH\" in properties:\n",
    "        has_switch_object.append(n.get(\"class_name\"))\n",
    "    if \"RECIPIENT\" in properties and \"POURABLE\" in properties:\n",
    "        drinkable_object.append(n.get(\"class_name\"))\n",
    "    if \"READABLE\" in properties:\n",
    "        readable_object.append(n.get(\"class_name\"))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_action(action_script, action, object, sitting):\n",
    "\n",
    "    if action in noObjAction:\n",
    "        if action == \"stand_up\":\n",
    "            if sitting == True:\n",
    "                action_script.append([\"stand_up\"])\n",
    "                sitting = False\n",
    "        else:\n",
    "            if sitting == True:\n",
    "                action_script.append([\"stand_up\"])\n",
    "                sitting = False\n",
    "            action_script.append([action])\n",
    "    \n",
    "    elif action==\"walk\" or action==\"run\":\n",
    "        if object:\n",
    "            if sitting == True:\n",
    "                action_script.append([\"stand_up\"])\n",
    "                sitting = False\n",
    "            action_script.append([action, object[0]])\n",
    "\n",
    "    elif action==\"find\":\n",
    "        if object[0] not in find_object:\n",
    "            if sitting == True:\n",
    "                action_script.append([\"stand_up\"])\n",
    "                sitting = False\n",
    "            action_script.append([\"walk\", object[0]])\n",
    "            action_script.append([\"find\", object[0]])\n",
    "            find_object.append(object[0])\n",
    "    \n",
    "    else:\n",
    "        if action not in noNeedToWalk:\n",
    "            if sitting == True:\n",
    "                action_script.append([\"stand_up\"])\n",
    "                sitting = False\n",
    "            action_script.append([\"walk\", object[0]]) #<- 距離を測ってwalkが必要かどうか\n",
    "\n",
    "        if object[0] not in find_object:\n",
    "            action_script.append([\"find\", object[0]])\n",
    "            find_object.append(object[0])\n",
    "\n",
    "\n",
    "        if action == \"sit\":\n",
    "            if (object[0] in sittable_object) and (sitting == False):\n",
    "                action_script.append([action, object[0]])\n",
    "                sitting = True\n",
    "\n",
    "        elif action == \"grab\":\n",
    "            if (object[0] in grabbable_object) and (object[0] not in grab_object) and (len(grab_object) < 2):\n",
    "                action_script.append([action, object[0]])\n",
    "                grab_object.append(object[0])\n",
    "\n",
    "        elif action == \"open\":\n",
    "            if (object[0] in can_open_object) and (object[0] not in open_object):\n",
    "                action_script.append([action, object[0]])\n",
    "                open_object.append([object[0]])\n",
    "\n",
    "        elif action == \"close\":\n",
    "            if object[0] in open_object:\n",
    "                action_script.append([action, object[0]])\n",
    "                open_object.remove([object[0]])\n",
    "\n",
    "        elif action == \"put_back\" and len(object) > 1:\n",
    "            if (object[0] in grabbable_object) and (object[0] not in grab_object) and (len(grab_object) < 2):\n",
    "                action_script.append([\"grab\", object[0]])\n",
    "                grab_object.append(object[0])\n",
    "\n",
    "            if object[0] in grab_object:\n",
    "                action_script.append([\"walk\", object[1]])\n",
    "                if object[1] not in find_object:\n",
    "                    action_script.append([\"find\", object[1]])\n",
    "                    find_object.append(object[1])\n",
    "\n",
    "                action_script.append([action, object[0], object[1]])\n",
    "                grab_object.remove(object[0])\n",
    "\n",
    "        elif action == \"put_in\" and len(object) > 1:\n",
    "            if (object[0] in grabbable_object) and (object[0] not in grab_object) and (len(grab_object) < 2):\n",
    "                action_script.append([\"grab\", object[0]])\n",
    "                grab_object.append(object[0])\n",
    "\n",
    "            if (object[0] in grab_object) and (object[1] in container_list):\n",
    "                action_script.append([\"walk\", object[1]])\n",
    "                if object[1] not in find_object:\n",
    "                    action_script.append([\"find\", object[1]])\n",
    "                    find_object.append(object[1])\n",
    "\n",
    "                if object[1] in can_open_object:\n",
    "                    if object[1] not in open_object:\n",
    "                        action_script.append([\"open\", object[1]])\n",
    "                        open_object.append([object[1]])\n",
    "                \n",
    "                action_script.append([action, object[0], object[1]])\n",
    "                grab_object.remove(object[0])\n",
    "\n",
    "        elif action == \"switch_on\":\n",
    "            if (object[0] in has_switch_object) and (object[0] not in switch_on_object):\n",
    "                action_script.append([action, object[0]])\n",
    "                switch_on_object.append([object[0]])\n",
    "\n",
    "        elif action == \"switch_off\":\n",
    "            if (object[0] in has_switch_object) and (object[0] in switch_on_object):\n",
    "                action_script.append([action, object[0]])\n",
    "                switch_on_object.remove([object[0]])\n",
    "\n",
    "        elif action == \"drink\":\n",
    "            if object[0] in drinkable_object:\n",
    "                if (object[0] in grabbable_object) and (object[0] not in grab_object) and (len(grab_object) < 2):\n",
    "                    action_script.append([\"grab\", object[0]])\n",
    "                    grab_object.append(object[0])\n",
    "                \n",
    "                if object[0] in grab_object:\n",
    "                    action_script.append([action, object[0]])\n",
    "\n",
    "        elif action == \"look_at\":\n",
    "            action_script.append([\"turn_to\", object[0]])\n",
    "            action_script.append([action, object[0]])\n",
    "\n",
    "        elif action == \"read\":\n",
    "            if object[0] in readable_object:\n",
    "                if (object[0] in grabbable_object) and (object[0] not in grab_object) and (len(grab_object) < 2):\n",
    "                    action_script.append([\"grab\", object[0]])\n",
    "                    grab_object.append(object[0])\n",
    "                \n",
    "                if object[0] in grab_object:\n",
    "                    action_script.append([action, object[0]])\n",
    "        \n",
    "        else: # action == \"touch\", \"watch\":\n",
    "            action_script.append([action, object[0]])\n",
    "    \n",
    "    return action_script, sitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_script(text):\n",
    "\n",
    "    action_script = []\n",
    "    hold_script = []\n",
    "    \n",
    "    #座っているかどうか\n",
    "    sitting = False\n",
    "\n",
    "    #現在いる部屋\n",
    "    current_location = \"\"\n",
    "\n",
    "    #依存構造解析の情報を保存 \n",
    "    row = morphological_analysis(nlp(text))\n",
    "    text_info = row[0]\n",
    "    sentence = row[1]\n",
    "    verb_list = [str(info.get(\"action\")).rsplit(\"_\")[0] for info in text_info] # 動詞の一覧\n",
    "\n",
    "    for num, info in enumerate(text_info):\n",
    "        if \"_\" in str(info.get(\"action\")): # 動詞+前置詞の場合 動詞と句動詞2パターンに分解\n",
    "            verb = str(info.get(\"action\")).rsplit(\"_\")[0]\n",
    "            pharasal_verb = str(info.get(\"action\"))\n",
    "        else:\n",
    "            verb = str(info.get(\"action\"))\n",
    "            pharasal_verb = None\n",
    "        \n",
    "        if verb_list[:num+1].count(verb) > 1: # 同じ動詞が存在する場合に前から何番目か計算 <- fill_mask で空欄にする場所を知っておきたい\n",
    "            row = decision_action_object(verb, pharasal_verb, info.get(\"object\"), sentence, verb_list[:num+1].count(verb)-1)\n",
    "        else:\n",
    "            row = decision_action_object(verb, pharasal_verb, info.get(\"object\"), sentence, 0)\n",
    "        action = row[0]\n",
    "        object = row[1]\n",
    "        #print(action, object)\n",
    "\n",
    "        #オブジェクトが存在する場合\n",
    "        if object and action:\n",
    "\n",
    "            #オブジェクトがある部屋をカウント\n",
    "            count = 0\n",
    "            for value in room_dict.values():\n",
    "                if object[0] in value:\n",
    "                    count += 1\n",
    "\n",
    "            #オブジェクトが部屋で，アクションが walk or run の場合\n",
    "            if object[0] in room_list and (action==\"walk\" or action==\"run\"):\n",
    "                current_location = object[0]\n",
    "                action_script.append([action, current_location])\n",
    "                #break\n",
    "            \n",
    "            #部屋がわからない or オブジェクトがある部屋が複数ある\n",
    "            elif count==0 or count>1:\n",
    "                \n",
    "                for key, value in room_dict.items():\n",
    "                    # 現在いる部屋にオブジェクトが存在する場合\n",
    "                    if object[0] in value and current_location == key:\n",
    "                        if hold_script:\n",
    "                            for hs in hold_script:\n",
    "                                action_script, sitting = add_action(action_script, hs[0], hs[1], sitting)\n",
    "                            hold_script = []\n",
    "\n",
    "                        action_script, sitting = add_action(action_script, action, object, sitting)\n",
    "\n",
    "                    # 現在いる部屋にオブジェクトが存在しなかった場合\n",
    "                    elif next(iter(reversed(room_dict))) == key: #next(iter(reversed(room_dict)))<- 最後の要素\n",
    "                        #一旦保留をする\n",
    "                        hold_script.append([action, object])\n",
    "                        #break\n",
    "\n",
    "            else:\n",
    "                #オブジェクトがバスルームにある\n",
    "                if object[0] in bathroom_objects:\n",
    "                    if current_location != \"bathroom\":\n",
    "                        current_location = \"bathroom\"\n",
    "                        action_script.append([\"walk\", current_location])\n",
    "\n",
    "                #オブジェクトがベッドルームにある\n",
    "                elif object[0] in bedroom_objects:\n",
    "                    if current_location != \"bedroom\":\n",
    "                        current_location = \"bedroom\"\n",
    "                        action_script.append([\"walk\", current_location])\n",
    "\n",
    "                #オブジェクトがダイニングルームにある\n",
    "                elif object[0] in kitchen_objects:\n",
    "                    if current_location != \"kitchen\":\n",
    "                        current_location = \"kitchen\"\n",
    "                        action_script.append([\"walk\", current_location])\n",
    "\n",
    "                #オブジェクトがホームオフィスにある\n",
    "                elif object[0] in livingroom_objects:\n",
    "                    if current_location != \"livingroom\": \n",
    "                        current_location = \"livingroom\"\n",
    "                        action_script.append([\"walk\", current_location])\n",
    "\n",
    "\n",
    "                #保留していたアクションがある場合，アクションスクリプトに追加\n",
    "                if hold_script:\n",
    "                    for hs in hold_script:\n",
    "                        action_script, sitting = add_action(action_script, hs[0], hs[1], sitting)\n",
    "                    hold_script = []\n",
    "\n",
    "                action_script, sitting = add_action(action_script, action, object, sitting)\n",
    "\n",
    "        elif hold_script:\n",
    "            if action in noObjAction:\n",
    "                hold_script.append([action])\n",
    "\n",
    "        else:\n",
    "            if action in noObjAction:\n",
    "                action_script.append([action])\n",
    "\n",
    "    if hold_script:\n",
    "        for hs in hold_script:\n",
    "            action_script, sitting = add_action(action_script, hs[0], hs[1], sitting)\n",
    "                  \n",
    "    return action_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['walk', 'bedroom'], ['walk', 'radio'], ['find', 'radio'], ['walk', 'radio'], ['switch_on', 'radio'], ['walk', 'livingroom'], ['walk', 'sofa'], ['find', 'sofa'], ['sit', 'sofa'], ['stand_up']]\n"
     ]
    }
   ],
   "source": [
    "activity_text = 'Find radio. Turn on radio. Find a station that you like by switching through the channels. Listen. I sit in the sofa. I stand up'\n",
    "find_object = [] \n",
    "\n",
    "script = generate_script(activity_text)\n",
    "print(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'category': 'Characters', 'class_name': 'character', 'prefab_name': 'Male1', 'obj_transform': {'position': [-6.45394659, 1.247, 1.34590578], 'rotation': [0.0, 0.260742217, 0.0, 0.9654085], 'scale': [1.0, 1.0, 1.0]}, 'bounding_box': {'center': [-3.289465, 0.878253043, -4.75412846], 'size': [0.921627045, 1.87452078, 1.4303093]}, 'properties': [], 'states': []}\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    script = ['<char0> [walk] <wallphone> (1)', '<char0> [find] <wallphone> (1)', '<char0> [grab] <wallphone> (1)'] # Add here your script\n",
    "    comm = UnityCommunication()\n",
    "    comm.reset(0)\n",
    "    comm.add_character('Chars/male1', initial_room='bathroom')\n",
    "    success, graph = comm.environment_graph()\n",
    "    a = comm.render_script(script=script, find_solution=True, skip_execution=False, recording=True, frame_rate=10, camera_mode=['AUTO'])\n",
    "    print(a)\n",
    "    \n",
    "    success, graph = comm.environment_graph()\n",
    "    character = [n for n in graph[\"nodes\"] if n.get(\"class_name\")==\"character\"][0]\n",
    "    print(character)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_action(action_script):\n",
    "    script = []\n",
    "    for action in action_script:\n",
    "        print(action[0])\n",
    "        action[0] = str(action[0]).replace(\"_\",\"\")\n",
    "        if len(action)==1:\n",
    "            script.append(f\"<char0> [{action[0]}]\")\n",
    "        elif len(action)==2:\n",
    "            script.append(f\"<char0> [{action[0]}] <{action[1]}> (1)\")\n",
    "        elif len(action)==3:\n",
    "            script.append(f\"<char0> [{action[0]}] <{action[1]}> (1) <{action[2]}> (1)\")\n",
    "    \n",
    "    comm.reset(0)\n",
    "    comm.add_character('Chars/male1', initial_room='bathroom')\n",
    "    success, graph = comm.environment_graph()\n",
    "    comm.render_script(script=script, find_solution=True, skip_execution=False, recording=True, frame_rate=10, camera_mode=['AUTO'])\n",
    "    print(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_script(text):\n",
    "\n",
    "    action_script = []\n",
    "    hold_script = []\n",
    "    \n",
    "    #座っているかどうか\n",
    "    sitting = False\n",
    "\n",
    "    #現在いる部屋\n",
    "    current_location = \"\"\n",
    "\n",
    "    #依存構造解析の情報を保存 \n",
    "    row = morphological_analysis(nlp(text))\n",
    "    text_info = row[0]\n",
    "    sentence = row[1]\n",
    "    verb_list = [str(info.get(\"action\")).rsplit(\"_\")[0] for info in text_info] # 動詞の一覧\n",
    "\n",
    "    for num, info in enumerate(text_info):\n",
    "        if \"_\" in str(info.get(\"action\")): # 動詞+前置詞の場合 動詞と句動詞2パターンに分解\n",
    "            verb = str(info.get(\"action\")).rsplit(\"_\")[0]\n",
    "            pharasal_verb = str(info.get(\"action\"))\n",
    "        else:\n",
    "            verb = str(info.get(\"action\"))\n",
    "            pharasal_verb = None\n",
    "        \n",
    "        if verb_list[:num+1].count(\"verb\") > 1: # 同じ動詞が存在する場合に前から何番目か計算 <- fill_mask で空欄にする場所を知っておきたい\n",
    "            row = decision_action_object(verb, pharasal_verb, info.get(\"object\"), sentence, verb_list[:num+1].count(\"verb\")-1)\n",
    "        else:\n",
    "            row = decision_action_object(verb, pharasal_verb, info.get(\"object\"), sentence, 0)\n",
    "        action = row[0]\n",
    "        object = row[1]\n",
    "        #print(action, object)\n",
    "\n",
    "        # アクションとオブジェクト両方ある場合\n",
    "        if action and object:\n",
    "            \n",
    "            # オブジェクトがある部屋をカウント\n",
    "            count = 0\n",
    "            for value in room_dict.values():\n",
    "                if object[0] in value:\n",
    "                    count += 1\n",
    "                    \n",
    "            # オブジェクトが部屋の場合\n",
    "            if object[0] in room_list and (action==\"walk\" or action==\"run\"):\n",
    "                action_script.append([action, object[0]])\n",
    "                current_location = object[0]\n",
    "                \n",
    "            # オブジェクトがある部屋が複数ある\n",
    "            elif count>1:\n",
    "                \n",
    "                for key, value in room_dict.items():\n",
    "                    # 現在いる部屋にオブジェクトが存在する場合\n",
    "                    if object[0] in value and current_location == key:\n",
    "                        # 保留しているアクションがある場合\n",
    "                        # code\n",
    "                        \n",
    "                        action_script, sitting = add_action(action_script, action, object, sitting)\n",
    "\n",
    "                    # 現在いる部屋にオブジェクトが存在しなかった場合\n",
    "                    else:\n",
    "                        #一旦保留をする\n",
    "                        hold_script.append([action, object])\n",
    "                        \n",
    "            #else:\n",
    "        \n",
    "        # アクションのみ存在する場合\n",
    "        elif action is None:\n",
    "            action_script, sitting = add_action(action_script, action, object, sitting)\n",
    "          \n",
    "    return action_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "text = \"I go to book, I go to sofa, I go to livingroom.\"\n",
    "\n",
    "row = morphological_analysis(nlp(text))\n",
    "text_info = row[0]\n",
    "sentence = row[1]\n",
    "verb_list = [str(info.get(\"action\")).rsplit(\"_\")[0] for info in text_info] # 動詞の一覧\n",
    "\n",
    "for num, info in enumerate(text_info):\n",
    "        if \"_\" in str(info.get(\"action\")): # 動詞+前置詞の場合 動詞と句動詞2パターンに分解\n",
    "            verb = str(info.get(\"action\")).rsplit(\"_\")[0]\n",
    "            pharasal_verb = str(info.get(\"action\"))\n",
    "        else:\n",
    "            verb = str(info.get(\"action\"))\n",
    "            pharasal_verb = None\n",
    "        \n",
    "        print(verb_list[:num+1].count(verb)-1)\n",
    "        if verb_list[:num+1].count(verb) > 1: # 同じ動詞が存在する場合に前から何番目か計算 <- fill_mask で空欄にする場所を知っておきたい\n",
    "            row = decision_action_object(verb, pharasal_verb, info.get(\"object\"), sentence, verb_list[:num+1].count(verb)-1)\n",
    "        else:\n",
    "            row = decision_action_object(verb, pharasal_verb, info.get(\"object\"), sentence, 0)\n",
    "        action = row[0]\n",
    "        object = row[1]\n",
    "        #print(action, object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vh2kg",
   "language": "python",
   "name": "vh2kg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "164b60b6cfc9b3a5d0e3da7c24e906e237438ca5bb19a3eb17752cc44c9505cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
